{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b718e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.models import all_models\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cfc9eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_net = all_models['VGG11_BN']()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70f1c775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9747136.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vgg_net)\n",
    "vgg_net.mask_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0724ca31",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pruneable' object has no attribute 'init_param_sizes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12645/646981078.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPruneable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPruneable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPruneable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_param_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1131\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pruneable' object has no attribute 'init_param_sizes'"
     ]
    }
   ],
   "source": [
    "from models.Pruneable import Pruneable\n",
    "p = Pruneable()\n",
    "p.init_param_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5c55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in vgg_net.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96de689",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([1, 2, 3, 4,5,6])\n",
    "b = torch.where(a>=1, 1, 0)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = vgg_net.state_dict()\n",
    "for name in params:\n",
    "    if name in vgg_net.mask.keys():\n",
    "        print(name)\n",
    "#     if 'weight' in name:\n",
    "#         print(name)\n",
    "#         print(params[name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in vgg_net.mask:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6e7d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.default_rng().choice(list([1,2,3]), 3, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in vgg_net.mask:\n",
    "    vgg_net.mask[name] = torch.zeros_like(vgg_net.mask[name], dtype=torch.float, device='cpu')\n",
    "\n",
    "vgg_net_cp = copy.deepcopy(vgg_net)\n",
    "for name in vgg_net_cp.mask:\n",
    "    print(vgg_net_cp.mask[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c50ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_idx = np.random.permutation(50000)\n",
    "train_idx = np.array(np.array_split(train_idx, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cde1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_idx.shape)\n",
    "print(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32151810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54791538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_list(x):\n",
    "    if x == 'cpu':\n",
    "        return [x]\n",
    "    return [int(y) for y in x.split(',')]\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--eta', type=float, help='learning rate', default=0.01)\n",
    "parser.add_argument('--clients', type=int, help='number of clients per round', default=20)\n",
    "parser.add_argument('--rounds', type=int, help='number of global rounds', default=400)\n",
    "parser.add_argument('--epochs', type=int, help='number of local epochs', default=10)\n",
    "parser.add_argument('--dataset', type=str, choices=('mnist', 'emnist', 'cifar10', 'cifar100'),\n",
    "                    default='mnist', help='Dataset to use')\n",
    "parser.add_argument('--distribution', type=str, choices=('dirichlet', 'lotteryfl', 'iid', 'classic_iid'), default='dirichlet',\n",
    "                    help='how should the dataset be distributed?')\n",
    "parser.add_argument('--beta', type=float, default=0.1, help='Beta parameter (unbalance rate) for Dirichlet distribution')\n",
    "parser.add_argument('--total-clients', type=int, help='split the dataset between this many clients. Ignored for EMNIST.', default=400)\n",
    "parser.add_argument('--min-samples', type=int, default=0, help='minimum number of samples required to allow a client to participate')\n",
    "parser.add_argument('--samples-per-client', type=int, default=20, help='samples to allocate to each client (per class, for lotteryfl, or per client, for iid)')\n",
    "parser.add_argument('--prox', type=float, default=0, help='coefficient to proximal term (i.e. in FedProx)')\n",
    "\n",
    "parser.add_argument('--batch-size', type=int, default=32,\n",
    "                    help='local client batch size')\n",
    "parser.add_argument('--l2', default=0.001, type=float, help='L2 regularization strength')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, help='Local client SGD momentum parameter')\n",
    "parser.add_argument('--cache-test-set', default=False, action='store_true', help='Load test sets into memory')\n",
    "parser.add_argument('--cache-test-set-gpu', default=False, action='store_true', help='Load test sets into GPU memory')\n",
    "parser.add_argument('--test-batches', default=0, type=int, help='Number of minibatches to test on, or 0 for all of them')\n",
    "parser.add_argument('--eval-every', default=1, type=int, help='Evaluate on test set every N rounds')\n",
    "parser.add_argument('--device', default='0', type=device_list, help='Device to use for compute. Use \"cpu\" to force CPU. Otherwise, separate with commas to allow multi-GPU.')\n",
    "parser.add_argument('--no-eval', default=True, action='store_false', dest='eval')\n",
    "parser.add_argument('-o', '--outfile', default='output.log', type=argparse.FileType('a', encoding='ascii'))\n",
    "\n",
    "\n",
    "parser.add_argument('--model', type=str, choices=('VGG11_BN', 'VGG_SNIP', 'CNNNet'),\n",
    "                    default='VGG11_BN', help='Dataset to use')\n",
    "\n",
    "parser.add_argument('--prune_strategy', type=str, choices=('None', 'SNIP'),\n",
    "                    default='None', help='Dataset to use')\n",
    "parser.add_argument('--prune_at_first_round', default=False, action='store_true', dest='prune_at_first_round')\n",
    "parser.add_argument('--keep_ratio', type=float, default=0.0,\n",
    "                    help='local client batch size')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f8387",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=['--eta', '0.005'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ac11a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models_bak as models\n",
    "from models_bak import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97b3e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = all_models['cifar10']('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adf76304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight\n",
      "bias\n",
      "weight\n",
      "bias\n",
      "weight\n",
      "bias\n",
      "weight\n",
      "bias\n",
      "weight\n",
      "bias\n"
     ]
    }
   ],
   "source": [
    "layers_to_prune = (layer for _, layer in net.named_children())\n",
    "for layer in layers_to_prune:\n",
    "    for name, param in layer.named_parameters():\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "506ecd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models import all_models\n",
    "net = all_models['VGG11_BN']('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b592ef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_weight\n",
      "0_bias\n",
      "1_weight\n",
      "1_bias\n",
      "4_weight\n",
      "4_bias\n",
      "5_weight\n",
      "5_bias\n",
      "8_weight\n",
      "8_bias\n",
      "9_weight\n",
      "9_bias\n",
      "11_weight\n",
      "11_bias\n",
      "12_weight\n",
      "12_bias\n",
      "15_weight\n",
      "15_bias\n",
      "16_weight\n",
      "16_bias\n",
      "18_weight\n",
      "18_bias\n",
      "19_weight\n",
      "19_bias\n",
      "22_weight\n",
      "22_bias\n",
      "23_weight\n",
      "23_bias\n",
      "25_weight\n",
      "25_bias\n",
      "26_weight\n",
      "26_bias\n",
      "0_weight\n",
      "0_bias\n",
      "1_weight\n",
      "1_bias\n",
      "3_weight\n",
      "3_bias\n",
      "4_weight\n",
      "4_bias\n",
      "6_weight\n",
      "6_bias\n"
     ]
    }
   ],
   "source": [
    "layers_to_prune = (layer for _, layer in net.named_children())\n",
    "for layer in layers_to_prune:\n",
    "    for name, param in layer.named_parameters():\n",
    "#         if '.' in name:\n",
    "#             name\n",
    "        name = name.replace('.', '_')\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49f2a6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: features.0.weight; shape: torch.Size([64, 3, 3, 3])\n",
      "name: features.0.bias; shape: torch.Size([64])\n",
      "name: features.1.weight; shape: torch.Size([64])\n",
      "name: features.1.bias; shape: torch.Size([64])\n",
      "name: features.1.running_mean; shape: torch.Size([64])\n",
      "name: features.1.running_var; shape: torch.Size([64])\n",
      "name: features.1.num_batches_tracked; shape: torch.Size([])\n",
      "name: features.4.weight; shape: torch.Size([128, 64, 3, 3])\n",
      "name: features.4.bias; shape: torch.Size([128])\n",
      "name: features.5.weight; shape: torch.Size([128])\n",
      "name: features.5.bias; shape: torch.Size([128])\n",
      "name: features.5.running_mean; shape: torch.Size([128])\n",
      "name: features.5.running_var; shape: torch.Size([128])\n",
      "name: features.5.num_batches_tracked; shape: torch.Size([])\n",
      "name: features.8.weight; shape: torch.Size([256, 128, 3, 3])\n",
      "name: features.8.bias; shape: torch.Size([256])\n",
      "name: features.9.weight; shape: torch.Size([256])\n",
      "name: features.9.bias; shape: torch.Size([256])\n",
      "name: features.9.running_mean; shape: torch.Size([256])\n",
      "name: features.9.running_var; shape: torch.Size([256])\n",
      "name: features.9.num_batches_tracked; shape: torch.Size([])\n",
      "name: features.11.weight; shape: torch.Size([256, 256, 3, 3])\n",
      "name: features.11.bias; shape: torch.Size([256])\n",
      "name: features.12.weight; shape: torch.Size([256])\n",
      "name: features.12.bias; shape: torch.Size([256])\n",
      "name: features.12.running_mean; shape: torch.Size([256])\n",
      "name: features.12.running_var; shape: torch.Size([256])\n",
      "name: features.12.num_batches_tracked; shape: torch.Size([])\n",
      "name: features.15.weight; shape: torch.Size([512, 256, 3, 3])\n",
      "name: features.15.bias; shape: torch.Size([512])\n",
      "name: features.16.weight; shape: torch.Size([512])\n",
      "name: features.16.bias; shape: torch.Size([512])\n",
      "name: features.16.running_mean; shape: torch.Size([512])\n",
      "name: features.16.running_var; shape: torch.Size([512])\n",
      "name: features.16.num_batches_tracked; shape: torch.Size([])\n",
      "name: features.18.weight; shape: torch.Size([512, 512, 3, 3])\n",
      "name: features.18.bias; shape: torch.Size([512])\n",
      "name: features.19.weight; shape: torch.Size([512])\n",
      "name: features.19.bias; shape: torch.Size([512])\n",
      "name: features.19.running_mean; shape: torch.Size([512])\n",
      "name: features.19.running_var; shape: torch.Size([512])\n",
      "name: features.19.num_batches_tracked; shape: torch.Size([])\n",
      "name: features.22.weight; shape: torch.Size([512, 512, 3, 3])\n",
      "name: features.22.bias; shape: torch.Size([512])\n",
      "name: features.23.weight; shape: torch.Size([512])\n",
      "name: features.23.bias; shape: torch.Size([512])\n",
      "name: features.23.running_mean; shape: torch.Size([512])\n",
      "name: features.23.running_var; shape: torch.Size([512])\n",
      "name: features.23.num_batches_tracked; shape: torch.Size([])\n",
      "name: features.25.weight; shape: torch.Size([512, 512, 3, 3])\n",
      "name: features.25.bias; shape: torch.Size([512])\n",
      "name: features.26.weight; shape: torch.Size([512])\n",
      "name: features.26.bias; shape: torch.Size([512])\n",
      "name: features.26.running_mean; shape: torch.Size([512])\n",
      "name: features.26.running_var; shape: torch.Size([512])\n",
      "name: features.26.num_batches_tracked; shape: torch.Size([])\n",
      "name: classifier.0.weight; shape: torch.Size([512])\n",
      "name: classifier.0.bias; shape: torch.Size([512])\n",
      "name: classifier.0.running_mean; shape: torch.Size([512])\n",
      "name: classifier.0.running_var; shape: torch.Size([512])\n",
      "name: classifier.0.num_batches_tracked; shape: torch.Size([])\n",
      "name: classifier.1.weight; shape: torch.Size([512, 512])\n",
      "name: classifier.1.bias; shape: torch.Size([512])\n",
      "name: classifier.3.weight; shape: torch.Size([512])\n",
      "name: classifier.3.bias; shape: torch.Size([512])\n",
      "name: classifier.3.running_mean; shape: torch.Size([512])\n",
      "name: classifier.3.running_var; shape: torch.Size([512])\n",
      "name: classifier.3.num_batches_tracked; shape: torch.Size([])\n",
      "name: classifier.4.weight; shape: torch.Size([512, 512])\n",
      "name: classifier.4.bias; shape: torch.Size([512])\n",
      "name: classifier.6.weight; shape: torch.Size([10, 512])\n",
      "name: classifier.6.bias; shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, params in net.state_dict().items():\n",
    "    print(f'name: {name}; shape: {params.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dffebd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Test(object):\n",
    "    @property\n",
    "    def t(self):\n",
    "        return 0\n",
    "t = Test()\n",
    "t.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c67c818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "weight\n",
      "bias\n",
      "Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "weight\n",
      "bias\n",
      "Linear(in_features=6400, out_features=120, bias=True)\n",
      "weight\n",
      "bias\n",
      "Linear(in_features=120, out_features=84, bias=True)\n",
      "weight\n",
      "bias\n",
      "Linear(in_features=84, out_features=10, bias=True)\n",
      "weight\n",
      "bias\n"
     ]
    }
   ],
   "source": [
    "from models_bak import vgg11_bn, CIFAR10Net\n",
    "import torch.nn as nn\n",
    "\n",
    "model = CIFAR10Net()\n",
    "\n",
    "# layers_to_prune = (layer for _, layer in model.named_children())\n",
    "# for layer in layers_to_prune:\n",
    "#     for name, param in layer.named_parameters():\n",
    "#         print(name)\n",
    "\n",
    "for i, (name, layer) in enumerate(model.named_children()):\n",
    "#     print(name)\n",
    "    print(layer)\n",
    "    for pname, param in layer.named_parameters():\n",
    "        print(pname)\n",
    "        \n",
    "#     if isinstance(layer, nn.modules.conv._ConvNd):\n",
    "#         print('Conv2d')\n",
    "#     elif isinstance(layer, nn.Linear):\n",
    "#         print('Linear')\n",
    "#     else:\n",
    "#         raise ValueError('Unsupported layer type ' + type(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b32a7476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "classifier\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# model = CIFAR10Net()\n",
    "model = vgg11_bn()\n",
    "layers_to_prune = (layer for _, layer in model.named_children())\n",
    "\n",
    "\n",
    "# for name, param in model.state_dict().items():\n",
    "#     print(name)\n",
    "for name, container in model.named_children():\n",
    "    print(name)\n",
    "    for name, layer in container.named_children():\n",
    "        print(name)\n",
    "#         for name, param in layer.named_parameters():\n",
    "#             print(1)\n",
    "# for _, layer in model.named_children():\n",
    "#     for name, param in layer.named_parameters():\n",
    "#         print(name)\n",
    "\n",
    "# for name, container in model.named_children():\n",
    "# #     print(container)\n",
    "#     for name, layer in container.named_children():\n",
    "#         print('*'*20)\n",
    "#         print(name)\n",
    "#         print(layer)\n",
    "#         if isinstance(layer, nn.modules.conv._ConvNd):\n",
    "#             print('Conv2d')\n",
    "#         elif isinstance(layer, nn.Linear):\n",
    "#             print('Linear')\n",
    "#         else:\n",
    "#             print('skiped')\n",
    "#             raise ValueError('Unsupported layer type ' + type(layer))\n",
    "#     print(container)\n",
    "#     for name, layer in container:\n",
    "#         print(name)\n",
    "\n",
    "# for layer in layers_to_prune:\n",
    "#     print(1)\n",
    "#     for name, param in layer.named_parameters():\n",
    "#         if name.endswith('weight'):\n",
    "# #             name = name.split('.')[-1]\n",
    "#             print(name)\n",
    "    \n",
    "#     if isinstance(layer, nn.modules.conv._ConvNd):\n",
    "#         print('Conv')\n",
    "#     elif isinstance(layer, nn.Linear):\n",
    "#         print('Linear')\n",
    "#     else:\n",
    "#         print(layer)\n",
    "#         raise ValueError('Unsupported layer type ' + type(layer))\n",
    "# for i, (name, layer) in enumerate(model.named_children()):\n",
    "#     print(layer)\n",
    "#     for l in layer:\n",
    "#         print(pname)\n",
    "\n",
    "#         if isinstance(layer, nn.modules.conv._ConvNd):\n",
    "#             print(True)\n",
    "#         elif isinstance(layer, nn.Linear):\n",
    "#             print('Linear')\n",
    "#         else:\n",
    "#             print(layer)\n",
    "#             raise ValueError('Unsupported layer type ' + type(layer))\n",
    "#     for i, (name, layer) in enumerate(layer.named_children()):\n",
    "#         print(name)\n",
    "#         for pname, param in layer.named_parameters():\n",
    "#             print(pname)\n",
    "\n",
    "#         if isinstance(layer, nn.modules.conv._ConvNd):\n",
    "#             print(True)\n",
    "#         elif isinstance(layer, nn.Linear):\n",
    "#             print('Linear')\n",
    "#         else:\n",
    "#             print(layer)\n",
    "#             raise ValueError('Unsupported layer type ' + type(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ca91cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight\n",
      "bias\n",
      "weight\n",
      "bias\n",
      "weight\n",
      "bias\n",
      "weight\n",
      "bias\n",
      "weight\n",
      "bias\n",
      "weight\n",
      "bias\n",
      "weight\n",
      "bias\n",
      "weight\n",
      "bias\n",
      "weight\n",
      "bias\n",
      "weight\n",
      "bias\n",
      "weight\n",
      "bias\n"
     ]
    }
   ],
   "source": [
    "from models_bak import VGG11_BN\n",
    "import torch.nn as nn\n",
    "model = VGG11_BN()\n",
    "for name, layer in model.named_children():\n",
    "    if (not isinstance(layer, nn.modules.conv._ConvNd)) and (not isinstance(layer, nn.Linear)):\n",
    "        continue\n",
    "    print(name)\n",
    "    for pname, param in layer.named_parameters():\n",
    "        print(pname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
