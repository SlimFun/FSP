{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc456178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import test\n",
    "import torch\n",
    "import torch.cuda\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import argparse\n",
    "import gc\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import copy\n",
    "\n",
    "import wandb\n",
    "\n",
    "from datasets import get_dataset\n",
    "from models.models import all_models\n",
    "\n",
    "from client import Client\n",
    "from utils import *\n",
    "\n",
    "import fedsnip_obj\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "def device_list(x):\n",
    "    if x == 'cpu':\n",
    "        return [x]\n",
    "    return [int(y) for y in x.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2442c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--prune_vote'], dest='prune_vote', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='local client batch size', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--eta', type=float, help='learning rate', default=0.01)\n",
    "parser.add_argument('--clients', type=int, help='number of clients per round', default=20)\n",
    "parser.add_argument('--rounds', type=int, help='number of global rounds', default=400)\n",
    "parser.add_argument('--epochs', type=int, help='number of local epochs', default=10)\n",
    "parser.add_argument('--dataset', type=str, choices=('mnist', 'emnist', 'cifar10', 'cifar100'),\n",
    "                    default='mnist', help='Dataset to use')\n",
    "parser.add_argument('--distribution', type=str, choices=('dirichlet', 'lotteryfl', 'iid', 'classic_iid'), default='dirichlet',\n",
    "                    help='how should the dataset be distributed?')\n",
    "parser.add_argument('--beta', type=float, default=0.1, help='Beta parameter (unbalance rate) for Dirichlet distribution')\n",
    "parser.add_argument('--total-clients', type=int, help='split the dataset between this many clients. Ignored for EMNIST.', default=400)\n",
    "parser.add_argument('--min-samples', type=int, default=0, help='minimum number of samples required to allow a client to participate')\n",
    "parser.add_argument('--samples-per-client', type=int, default=20, help='samples to allocate to each client (per class, for lotteryfl, or per client, for iid)')\n",
    "parser.add_argument('--prox', type=float, default=0, help='coefficient to proximal term (i.e. in FedProx)')\n",
    "\n",
    "parser.add_argument('--batch-size', type=int, default=32,\n",
    "                    help='local client batch size')\n",
    "parser.add_argument('--l2', default=0.001, type=float, help='L2 regularization strength')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, help='Local client SGD momentum parameter')\n",
    "parser.add_argument('--cache-test-set', default=False, action='store_true', help='Load test sets into memory')\n",
    "parser.add_argument('--cache-test-set-gpu', default=False, action='store_true', help='Load test sets into GPU memory')\n",
    "parser.add_argument('--test-batches', default=0, type=int, help='Number of minibatches to test on, or 0 for all of them')\n",
    "parser.add_argument('--eval-every', default=1, type=int, help='Evaluate on test set every N rounds')\n",
    "parser.add_argument('--device', default='0', type=device_list, help='Device to use for compute. Use \"cpu\" to force CPU. Otherwise, separate with commas to allow multi-GPU.')\n",
    "parser.add_argument('--no-eval', default=True, action='store_false', dest='eval')\n",
    "parser.add_argument('-o', '--outfile', default='output.log', type=argparse.FileType('a', encoding='ascii'))\n",
    "\n",
    "\n",
    "parser.add_argument('--model', type=str, choices=('VGG11_BN', 'VGG_SNIP', 'CNNNet'),\n",
    "                    default='VGG11_BN', help='Dataset to use')\n",
    "\n",
    "parser.add_argument('--prune_strategy', type=str, choices=('None', 'SNIP'),\n",
    "                    default='None', help='Dataset to use')\n",
    "parser.add_argument('--prune_at_first_round', default=False, action='store_true', dest='prune_at_first_round')\n",
    "parser.add_argument('--keep_ratio', type=float, default=0.0,\n",
    "                    help='local client batch size')    \n",
    "parser.add_argument('--prune_vote', type=int, default=1,\n",
    "                    help='local client batch size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70641184",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=['--dataset', 'cifar10', \n",
    "                               '--eta', '0.01', \n",
    "                               '--device', '3', \n",
    "                               '--distribution', 'classic_iid', \n",
    "                               '--total-clients', '10', \n",
    "                               '--clients', '10', \n",
    "                               '--batch-size', '64', \n",
    "                               '--rounds', '100', \n",
    "                               '--model', 'VGG11_BN', \n",
    "                               '--prune_strategy', 'SNIP',\n",
    "                               '--epochs', '2',\n",
    "                               '--keep_ratio', '0.1',\n",
    "                               '--prune_vote', '1',\n",
    "                               '--prune_at_first_round'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c79bb23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddbb79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = fedsnip_obj.main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0fff754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# print('...')\n",
    "# name = input()\n",
    "# print('++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88461634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching dataset...\n",
      "INFO:root:*********partition data***************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download = True\n",
      "Files already downloaded and verified\n",
      "download = True\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:traindata_cls_counts = {0: {0: 503, 1: 483, 2: 487, 3: 527, 4: 473, 5: 548, 6: 491, 7: 502, 8: 482, 9: 504}, 1: {0: 501, 1: 503, 2: 529, 3: 503, 4: 494, 5: 468, 6: 462, 7: 497, 8: 507, 9: 536}, 2: {0: 510, 1: 540, 2: 498, 3: 461, 4: 516, 5: 483, 6: 502, 7: 515, 8: 492, 9: 483}, 3: {0: 487, 1: 487, 2: 493, 3: 498, 4: 523, 5: 482, 6: 500, 7: 487, 8: 495, 9: 548}, 4: {0: 505, 1: 480, 2: 488, 3: 488, 4: 480, 5: 509, 6: 537, 7: 490, 8: 490, 9: 533}, 5: {0: 504, 1: 480, 2: 511, 3: 494, 4: 530, 5: 509, 6: 521, 7: 489, 8: 490, 9: 472}, 6: {0: 512, 1: 509, 2: 512, 3: 488, 4: 488, 5: 465, 6: 490, 7: 538, 8: 506, 9: 492}, 7: {0: 472, 1: 521, 2: 463, 3: 549, 4: 502, 5: 515, 6: 518, 7: 496, 8: 479, 9: 485}, 8: {0: 505, 1: 485, 2: 487, 3: 505, 4: 497, 5: 512, 6: 508, 7: 501, 8: 531, 9: 469}, 9: {0: 501, 1: 512, 2: 532, 3: 487, 4: 497, 5: 509, 6: 471, 7: 485, 8: 528, 9: 478}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000******************\n",
      "download = True\n",
      "Files already downloaded and verified\n",
      "download = True\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:seed: 0!!!!!!!\n",
      "INFO:root:train_dl_global number = 782\n",
      "INFO:root:test_dl_global number = 157\n",
      "INFO:root:client_idx = 0, local_sample_number = 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download = True\n",
      "Files already downloaded and verified\n",
      "download = True\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:seed: 0!!!!!!!\n",
      "INFO:root:client_idx = 0, batch_num_train_local = 79, batch_num_test_local = 16\n",
      "INFO:root:client_idx = 1, local_sample_number = 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download = True\n",
      "Files already downloaded and verified\n",
      "download = True\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:seed: 0!!!!!!!\n",
      "INFO:root:client_idx = 1, batch_num_train_local = 79, batch_num_test_local = 16\n",
      "INFO:root:client_idx = 2, local_sample_number = 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download = True\n",
      "Files already downloaded and verified\n",
      "download = True\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:seed: 0!!!!!!!\n",
      "INFO:root:client_idx = 2, batch_num_train_local = 79, batch_num_test_local = 16\n",
      "INFO:root:client_idx = 3, local_sample_number = 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download = True\n",
      "Files already downloaded and verified\n",
      "download = True\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:seed: 0!!!!!!!\n",
      "INFO:root:client_idx = 3, batch_num_train_local = 79, batch_num_test_local = 16\n",
      "INFO:root:client_idx = 4, local_sample_number = 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download = True\n",
      "Files already downloaded and verified\n",
      "download = True\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:seed: 0!!!!!!!\n",
      "INFO:root:client_idx = 4, batch_num_train_local = 79, batch_num_test_local = 16\n",
      "INFO:root:client_idx = 5, local_sample_number = 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download = True\n",
      "Files already downloaded and verified\n",
      "download = True\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:seed: 0!!!!!!!\n",
      "INFO:root:client_idx = 5, batch_num_train_local = 79, batch_num_test_local = 16\n",
      "INFO:root:client_idx = 6, local_sample_number = 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download = True\n",
      "Files already downloaded and verified\n",
      "download = True\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:seed: 0!!!!!!!\n",
      "INFO:root:client_idx = 6, batch_num_train_local = 79, batch_num_test_local = 16\n",
      "INFO:root:client_idx = 7, local_sample_number = 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download = True\n",
      "Files already downloaded and verified\n",
      "download = True\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:seed: 0!!!!!!!\n",
      "INFO:root:client_idx = 7, batch_num_train_local = 79, batch_num_test_local = 16\n",
      "INFO:root:client_idx = 8, local_sample_number = 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download = True\n",
      "Files already downloaded and verified\n",
      "download = True\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:seed: 0!!!!!!!\n",
      "INFO:root:client_idx = 8, batch_num_train_local = 79, batch_num_test_local = 16\n",
      "INFO:root:client_idx = 9, local_sample_number = 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download = True\n",
      "Files already downloaded and verified\n",
      "download = True\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:seed: 0!!!!!!!\n",
      "INFO:root:client_idx = 9, batch_num_train_local = 79, batch_num_test_local = 16\n",
      "Initializing clients...\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mslimfun\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/slimfun/feddst/runs/aaqxml23\" target=\"_blank\">FedDST(d)</a></strong> to <a href=\"https://wandb.ai/slimfun/feddst\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client: 3 **************\n",
      "all params num: 9747136; num_params_to_keep: 8772422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fw/anaconda3/envs/fedml/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8772422, device='cuda:3')\n",
      "client.net: 0.10096911377349008\n",
      "**********test before train*************\n",
      "test global model: 0.10096911377349008\n",
      "Test client 3: Accuracy: 0.09779999405145645; Loss: 2.30259370803833; Total: 5000.0;\n",
      "accuracy: 0.09779999405145645; loss: 2.30259370803833\n",
      "**********test before train*************\n",
      "running loss: 2.0603887551947486\n",
      "running loss: 1.8130085649369638\n",
      "total:  10000.0\n",
      "client: 6 **************\n",
      "all params num: 9747136; num_params_to_keep: 8772422\n",
      "tensor(8772422, device='cuda:3')\n",
      "client.net: 0.10096921616918061\n",
      "**********test before train*************\n",
      "test global model: 0.10096921616918061\n",
      "Test client 6: Accuracy: 0.09299999475479126; Loss: 2.3026037216186523; Total: 5000.0;\n",
      "accuracy: 0.09299999475479126; loss: 2.3026037216186523\n",
      "**********test before train*************\n",
      "running loss: 2.0807727424404288\n",
      "running loss: 1.817297027080874\n",
      "total:  10000.0\n",
      "client: 4 **************\n",
      "all params num: 9747136; num_params_to_keep: 8772422\n",
      "tensor(8772422, device='cuda:3')\n",
      "client.net: 0.10096921616918061\n",
      "**********test before train*************\n",
      "test global model: 0.10096921616918061\n",
      "Test client 4: Accuracy: 0.09319999814033508; Loss: 2.3025975227355957; Total: 5000.0;\n",
      "accuracy: 0.09319999814033508; loss: 2.3025975227355957\n",
      "**********test before train*************\n",
      "running loss: 2.0629160434384888\n",
      "running loss: 1.8234099466589433\n",
      "total:  10000.0\n",
      "client: 8 **************\n",
      "all params num: 9747136; num_params_to_keep: 8772422\n",
      "tensor(8772422, device='cuda:3')\n",
      "client.net: 0.10096911377349008\n",
      "**********test before train*************\n",
      "test global model: 0.10096911377349008\n",
      "Test client 8: Accuracy: 0.10279999673366547; Loss: 2.3025877475738525; Total: 5000.0;\n",
      "accuracy: 0.10279999673366547; loss: 2.3025877475738525\n",
      "**********test before train*************\n",
      "running loss: 2.067547069320196\n",
      "running loss: 1.7769448938249033\n",
      "total:  10000.0\n",
      "client: 0 **************\n",
      "all params num: 9747136; num_params_to_keep: 8772422\n",
      "tensor(8772422, device='cuda:3')\n",
      "client.net: 0.10096901137779955\n",
      "**********test before train*************\n",
      "test global model: 0.10096901137779955\n",
      "Test client 0: Accuracy: 0.1096000000834465; Loss: 2.3025879859924316; Total: 5000.0;\n",
      "accuracy: 0.1096000000834465; loss: 2.3025879859924316\n",
      "**********test before train*************\n",
      "running loss: 2.0620013022724586\n",
      "running loss: 1.7519114032576355\n",
      "total:  10000.0\n",
      "client: 5 **************\n",
      "all params num: 9747136; num_params_to_keep: 8772422\n",
      "tensor(8772422, device='cuda:3')\n",
      "client.net: 0.10096911377349008\n",
      "**********test before train*************\n",
      "test global model: 0.10096911377349008\n",
      "Test client 5: Accuracy: 0.0989999994635582; Loss: 2.3025901317596436; Total: 5000.0;\n",
      "accuracy: 0.0989999994635582; loss: 2.3025901317596436\n",
      "**********test before train*************\n",
      "running loss: 2.068405736850787\n",
      "running loss: 1.775097196615195\n",
      "total:  10000.0\n",
      "client: 2 **************\n",
      "all params num: 9747136; num_params_to_keep: 8772422\n",
      "tensor(8772422, device='cuda:3')\n",
      "client.net: 0.10096921616918061\n",
      "**********test before train*************\n",
      "test global model: 0.10096921616918061\n",
      "Test client 2: Accuracy: 0.10520000010728836; Loss: 2.3025963306427; Total: 5000.0;\n",
      "accuracy: 0.10520000010728836; loss: 2.3025963306427\n",
      "**********test before train*************\n",
      "running loss: 2.068564327457283\n",
      "running loss: 1.8028952607625648\n",
      "total:  10000.0\n",
      "client: 9 **************\n",
      "all params num: 9747136; num_params_to_keep: 8772422\n",
      "tensor(8772422, device='cuda:3')\n",
      "client.net: 0.10096911377349008\n",
      "**********test before train*************\n",
      "test global model: 0.10096911377349008\n",
      "Test client 9: Accuracy: 0.10199999809265137; Loss: 2.3025970458984375; Total: 5000.0;\n",
      "accuracy: 0.10199999809265137; loss: 2.3025970458984375\n",
      "**********test before train*************\n",
      "running loss: 2.076722295978401\n",
      "running loss: 1.8080270033848436\n",
      "total:  10000.0\n",
      "client: 7 **************\n",
      "all params num: 9747136; num_params_to_keep: 8772422\n",
      "tensor(8772422, device='cuda:3')\n",
      "client.net: 0.10096901137779955\n",
      "**********test before train*************\n",
      "test global model: 0.10096901137779955\n",
      "Test client 7: Accuracy: 0.10300000011920929; Loss: 2.302591562271118; Total: 5000.0;\n",
      "accuracy: 0.10300000011920929; loss: 2.302591562271118\n",
      "**********test before train*************\n",
      "running loss: 2.0750858874260625\n",
      "running loss: 1.8000671818286558\n",
      "total:  10000.0\n",
      "client: 1 **************\n",
      "all params num: 9747136; num_params_to_keep: 8772422\n",
      "tensor(8772422, device='cuda:3')\n",
      "client.net: 0.10096921616918061\n",
      "**********test before train*************\n",
      "test global model: 0.10096921616918061\n",
      "Test client 1: Accuracy: 0.09359999746084213; Loss: 2.3025970458984375; Total: 5000.0;\n",
      "accuracy: 0.09359999746084213; loss: 2.3025970458984375\n",
      "**********test before train*************\n",
      "running loss: 2.073791365080242\n",
      "running loss: 1.7852404177943362\n",
      "total:  10000.0\n"
     ]
    }
   ],
   "source": [
    "# while True:\n",
    "#     debug_info = next(run)\n",
    "#     print(debug_info.msg)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     input()\n",
    "debug_info = next(run)\n",
    "(model_list, server) = debug_info.obj\n",
    "# global_model = debug_info.obj\n",
    "# aggregated_masks = debug_info.obj[0]\n",
    "# cl_mask_prarms = debug_info.obj[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f36caac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight\n",
      "features.0.bias\n",
      "features.1.weight\n",
      "features.1.bias\n",
      "features.1.running_mean\n",
      "features.1.running_var\n",
      "features.1.num_batches_tracked\n",
      "features.4.weight\n",
      "features.4.bias\n",
      "features.5.weight\n",
      "features.5.bias\n",
      "features.5.running_mean\n",
      "features.5.running_var\n",
      "features.5.num_batches_tracked\n",
      "features.8.weight\n",
      "features.8.bias\n",
      "features.9.weight\n",
      "features.9.bias\n",
      "features.9.running_mean\n",
      "features.9.running_var\n",
      "features.9.num_batches_tracked\n",
      "features.11.weight\n",
      "features.11.bias\n",
      "features.12.weight\n",
      "features.12.bias\n",
      "features.12.running_mean\n",
      "features.12.running_var\n",
      "features.12.num_batches_tracked\n",
      "features.15.weight\n",
      "features.15.bias\n",
      "features.16.weight\n",
      "features.16.bias\n",
      "features.16.running_mean\n",
      "features.16.running_var\n",
      "features.16.num_batches_tracked\n",
      "features.18.weight\n",
      "features.18.bias\n",
      "features.19.weight\n",
      "features.19.bias\n",
      "features.19.running_mean\n",
      "features.19.running_var\n",
      "features.19.num_batches_tracked\n",
      "features.22.weight\n",
      "features.22.bias\n",
      "features.23.weight\n",
      "features.23.bias\n",
      "features.23.running_mean\n",
      "features.23.running_var\n",
      "features.23.num_batches_tracked\n",
      "features.25.weight\n",
      "features.25.bias\n",
      "features.26.weight\n",
      "features.26.bias\n",
      "features.26.running_mean\n",
      "features.26.running_var\n",
      "features.26.num_batches_tracked\n",
      "classifier.0.weight\n",
      "classifier.0.bias\n",
      "classifier.0.running_mean\n",
      "classifier.0.running_var\n",
      "classifier.0.num_batches_tracked\n",
      "classifier.1.weight\n",
      "classifier.1.bias\n",
      "classifier.3.weight\n",
      "classifier.3.bias\n",
      "classifier.3.running_mean\n",
      "classifier.3.running_var\n",
      "classifier.3.num_batches_tracked\n",
      "classifier.4.weight\n",
      "classifier.4.bias\n",
      "classifier.6.weight\n",
      "classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "for name in model_list[0][1]:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cad0f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.0000,  1.0000,  1.0000],\n",
      "          [ 0.1049, -0.1265, -0.1936],\n",
      "          [-0.0625, -0.0272, -0.0316]],\n",
      "\n",
      "         [[ 0.0058,  0.1236, -0.0714],\n",
      "          [-0.0846, -0.1164, -0.0325],\n",
      "          [ 0.0175,  0.0043, -0.0027]],\n",
      "\n",
      "         [[ 0.0998,  0.0625,  0.1206],\n",
      "          [-0.0531,  0.0409,  0.0927],\n",
      "          [ 0.0288, -0.0765, -0.0134]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0344, -0.0587,  0.0657],\n",
      "          [ 0.0144,  0.0120, -0.0016],\n",
      "          [-0.0919,  0.0136, -0.1024]],\n",
      "\n",
      "         [[-0.0150, -0.0258,  0.0599],\n",
      "          [ 0.0326,  0.0198, -0.1006],\n",
      "          [-0.0442, -0.0429,  0.0281]],\n",
      "\n",
      "         [[ 0.0212,  0.0103,  0.0838],\n",
      "          [ 0.0230,  0.0054,  0.0017],\n",
      "          [ 0.0207, -0.0553,  0.0938]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0452, -0.0017,  0.0452],\n",
      "          [-0.1510, -0.0091,  0.0583],\n",
      "          [-0.0034, -0.0743,  0.0394]],\n",
      "\n",
      "         [[ 0.0248, -0.0313,  0.0188],\n",
      "          [-0.0356,  0.0159,  0.0717],\n",
      "          [ 0.0557, -0.0710, -0.0214]],\n",
      "\n",
      "         [[ 0.0652,  0.0156,  0.1431],\n",
      "          [ 0.0402, -0.0117,  0.0381],\n",
      "          [-0.0715,  0.0636, -0.0568]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0806, -0.0125,  0.0389],\n",
      "          [ 0.0668, -0.0111,  0.0066],\n",
      "          [ 0.0250,  0.0721, -0.0192]],\n",
      "\n",
      "         [[-0.0228,  0.0730,  0.0115],\n",
      "          [-0.0606, -0.0061,  0.0607],\n",
      "          [ 0.0220, -0.0082, -0.0418]],\n",
      "\n",
      "         [[-0.0629, -0.0494,  0.0078],\n",
      "          [ 0.0028, -0.0543,  0.0262],\n",
      "          [ 0.1115,  0.0531,  0.0242]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1168,  0.0497,  0.0569],\n",
      "          [ 0.0382,  0.0765,  0.0599],\n",
      "          [ 0.0526, -0.0219, -0.0227]],\n",
      "\n",
      "         [[ 0.0457, -0.0018, -0.0658],\n",
      "          [ 0.0101,  0.0045, -0.1016],\n",
      "          [-0.0089, -0.0717,  0.0460]],\n",
      "\n",
      "         [[-0.0623,  0.0398,  0.0511],\n",
      "          [-0.0750,  0.0204, -0.0045],\n",
      "          [-0.0289, -0.0953,  0.0658]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0152,  0.0273,  0.0861],\n",
      "          [ 0.1204, -0.0482, -0.0349],\n",
      "          [-0.0038,  0.1237, -0.0803]],\n",
      "\n",
      "         [[ 0.0726,  0.0166, -0.0291],\n",
      "          [ 0.0320, -0.1162,  0.0146],\n",
      "          [-0.0378, -0.0317,  0.0700]],\n",
      "\n",
      "         [[-0.0769, -0.0688,  0.0948],\n",
      "          [ 0.0319, -0.0975, -0.0132],\n",
      "          [-0.0248, -0.0012,  0.0782]]]])\n",
      "*********************************\n",
      "tensor([[[[ 2.0000e+00,  2.0000e+00,  2.0000e+00],\n",
      "          [ 1.0486e-01, -1.2646e-01, -1.9363e-01],\n",
      "          [-6.2482e-02, -2.7194e-02, -3.1581e-02]],\n",
      "\n",
      "         [[ 5.8182e-03,  1.2362e-01, -7.1407e-02],\n",
      "          [-8.4556e-02, -1.1635e-01, -3.2457e-02],\n",
      "          [ 1.7546e-02,  4.3325e-03, -2.7413e-03]],\n",
      "\n",
      "         [[ 9.9801e-02,  6.2532e-02,  1.2058e-01],\n",
      "          [-5.3125e-02,  4.0899e-02,  9.2724e-02],\n",
      "          [ 2.8785e-02, -7.6549e-02, -1.3428e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4421e-02, -5.8660e-02,  6.5669e-02],\n",
      "          [ 1.4445e-02,  1.1984e-02, -1.6301e-03],\n",
      "          [-9.1897e-02,  1.3584e-02, -1.0243e-01]],\n",
      "\n",
      "         [[-1.4994e-02, -2.5800e-02,  5.9886e-02],\n",
      "          [ 3.2601e-02,  1.9766e-02, -1.0056e-01],\n",
      "          [-4.4194e-02, -4.2937e-02,  2.8116e-02]],\n",
      "\n",
      "         [[ 2.1219e-02,  1.0341e-02,  8.3762e-02],\n",
      "          [ 2.2954e-02,  5.3903e-03,  1.6704e-03],\n",
      "          [ 2.0700e-02, -5.5276e-02,  9.3754e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5157e-02, -1.7118e-03,  4.5232e-02],\n",
      "          [-1.5104e-01, -9.1112e-03,  5.8280e-02],\n",
      "          [-3.4326e-03, -7.4290e-02,  3.9359e-02]],\n",
      "\n",
      "         [[ 2.4752e-02, -3.1258e-02,  1.8828e-02],\n",
      "          [-3.5563e-02,  1.5901e-02,  7.1747e-02],\n",
      "          [ 5.5712e-02, -7.0957e-02, -2.1432e-02]],\n",
      "\n",
      "         [[ 6.5180e-02,  1.5617e-02,  1.4308e-01],\n",
      "          [ 4.0203e-02, -1.1701e-02,  3.8141e-02],\n",
      "          [-7.1505e-02,  6.3646e-02, -5.6842e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 8.0632e-02, -1.2547e-02,  3.8946e-02],\n",
      "          [ 6.6782e-02, -1.1109e-02,  6.5704e-03],\n",
      "          [ 2.5041e-02,  7.2126e-02, -1.9159e-02]],\n",
      "\n",
      "         [[-2.2761e-02,  7.2993e-02,  1.1535e-02],\n",
      "          [-6.0630e-02, -6.0811e-03,  6.0657e-02],\n",
      "          [ 2.2016e-02, -8.2487e-03, -4.1754e-02]],\n",
      "\n",
      "         [[-6.2861e-02, -4.9406e-02,  7.8330e-03],\n",
      "          [ 2.7555e-03, -5.4294e-02,  2.6224e-02],\n",
      "          [ 1.1154e-01,  5.3070e-02,  2.4227e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1675e-01,  4.9719e-02,  5.6871e-02],\n",
      "          [ 3.8235e-02,  7.6453e-02,  5.9894e-02],\n",
      "          [ 5.2568e-02, -2.1904e-02, -2.2721e-02]],\n",
      "\n",
      "         [[ 4.5724e-02, -1.7709e-03, -6.5810e-02],\n",
      "          [ 1.0073e-02,  4.5196e-03, -1.0164e-01],\n",
      "          [-8.9264e-03, -7.1688e-02,  4.6021e-02]],\n",
      "\n",
      "         [[-6.2287e-02,  3.9760e-02,  5.1084e-02],\n",
      "          [-7.5015e-02,  2.0439e-02, -4.4860e-03],\n",
      "          [-2.8926e-02, -9.5331e-02,  6.5784e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5184e-02,  2.7330e-02,  8.6135e-02],\n",
      "          [ 1.2042e-01, -4.8241e-02, -3.4874e-02],\n",
      "          [-3.7796e-03,  1.2365e-01, -8.0309e-02]],\n",
      "\n",
      "         [[ 7.2562e-02,  1.6589e-02, -2.9059e-02],\n",
      "          [ 3.2043e-02, -1.1624e-01,  1.4578e-02],\n",
      "          [-3.7848e-02, -3.1671e-02,  7.0038e-02]],\n",
      "\n",
      "         [[-7.6925e-02, -6.8776e-02,  9.4808e-02],\n",
      "          [ 3.1931e-02, -9.7486e-02, -1.3214e-02],\n",
      "          [-2.4765e-02, -1.2000e-03,  7.8210e-02]]]])\n",
      "tensor([[[[ 2.0000e+00,  2.0000e+00,  2.0000e+00],\n",
      "          [ 1.0486e-01, -1.2646e-01, -1.9363e-01],\n",
      "          [-6.2482e-02, -2.7194e-02, -3.1581e-02]],\n",
      "\n",
      "         [[ 5.8182e-03,  1.2362e-01, -7.1407e-02],\n",
      "          [-8.4556e-02, -1.1635e-01, -3.2457e-02],\n",
      "          [ 1.7546e-02,  4.3325e-03, -2.7413e-03]],\n",
      "\n",
      "         [[ 9.9801e-02,  6.2532e-02,  1.2058e-01],\n",
      "          [-5.3125e-02,  4.0899e-02,  9.2724e-02],\n",
      "          [ 2.8785e-02, -7.6549e-02, -1.3428e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4421e-02, -5.8660e-02,  6.5669e-02],\n",
      "          [ 1.4445e-02,  1.1984e-02, -1.6301e-03],\n",
      "          [-9.1897e-02,  1.3584e-02, -1.0243e-01]],\n",
      "\n",
      "         [[-1.4994e-02, -2.5800e-02,  5.9886e-02],\n",
      "          [ 3.2601e-02,  1.9766e-02, -1.0056e-01],\n",
      "          [-4.4194e-02, -4.2937e-02,  2.8116e-02]],\n",
      "\n",
      "         [[ 2.1219e-02,  1.0341e-02,  8.3762e-02],\n",
      "          [ 2.2954e-02,  5.3903e-03,  1.6704e-03],\n",
      "          [ 2.0700e-02, -5.5276e-02,  9.3754e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5157e-02, -1.7118e-03,  4.5232e-02],\n",
      "          [-1.5104e-01, -9.1112e-03,  5.8280e-02],\n",
      "          [-3.4326e-03, -7.4290e-02,  3.9359e-02]],\n",
      "\n",
      "         [[ 2.4752e-02, -3.1258e-02,  1.8828e-02],\n",
      "          [-3.5563e-02,  1.5901e-02,  7.1747e-02],\n",
      "          [ 5.5712e-02, -7.0957e-02, -2.1432e-02]],\n",
      "\n",
      "         [[ 6.5180e-02,  1.5617e-02,  1.4308e-01],\n",
      "          [ 4.0203e-02, -1.1701e-02,  3.8141e-02],\n",
      "          [-7.1505e-02,  6.3646e-02, -5.6842e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 8.0632e-02, -1.2547e-02,  3.8946e-02],\n",
      "          [ 6.6782e-02, -1.1109e-02,  6.5704e-03],\n",
      "          [ 2.5041e-02,  7.2126e-02, -1.9159e-02]],\n",
      "\n",
      "         [[-2.2761e-02,  7.2993e-02,  1.1535e-02],\n",
      "          [-6.0630e-02, -6.0811e-03,  6.0657e-02],\n",
      "          [ 2.2016e-02, -8.2487e-03, -4.1754e-02]],\n",
      "\n",
      "         [[-6.2861e-02, -4.9406e-02,  7.8330e-03],\n",
      "          [ 2.7555e-03, -5.4294e-02,  2.6224e-02],\n",
      "          [ 1.1154e-01,  5.3070e-02,  2.4227e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1675e-01,  4.9719e-02,  5.6871e-02],\n",
      "          [ 3.8235e-02,  7.6453e-02,  5.9894e-02],\n",
      "          [ 5.2568e-02, -2.1904e-02, -2.2721e-02]],\n",
      "\n",
      "         [[ 4.5724e-02, -1.7709e-03, -6.5810e-02],\n",
      "          [ 1.0073e-02,  4.5196e-03, -1.0164e-01],\n",
      "          [-8.9264e-03, -7.1688e-02,  4.6021e-02]],\n",
      "\n",
      "         [[-6.2287e-02,  3.9760e-02,  5.1084e-02],\n",
      "          [-7.5015e-02,  2.0439e-02, -4.4860e-03],\n",
      "          [-2.8926e-02, -9.5331e-02,  6.5784e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5184e-02,  2.7330e-02,  8.6135e-02],\n",
      "          [ 1.2042e-01, -4.8241e-02, -3.4874e-02],\n",
      "          [-3.7796e-03,  1.2365e-01, -8.0309e-02]],\n",
      "\n",
      "         [[ 7.2562e-02,  1.6589e-02, -2.9059e-02],\n",
      "          [ 3.2043e-02, -1.1624e-01,  1.4578e-02],\n",
      "          [-3.7848e-02, -3.1671e-02,  7.0038e-02]],\n",
      "\n",
      "         [[-7.6925e-02, -6.8776e-02,  9.4808e-02],\n",
      "          [ 3.1931e-02, -9.7486e-02, -1.3214e-02],\n",
      "          [-2.4765e-02, -1.2000e-03,  7.8210e-02]]]])\n"
     ]
    }
   ],
   "source": [
    "# for name in server.model.state_dict():\n",
    "#     print(name)\n",
    "server.model = server.model.to('cuda:3')\n",
    "params = server.model.cpu().state_dict()\n",
    "print(params['features.0.weight'])\n",
    "\n",
    "print('***********'*3)\n",
    "\n",
    "# params['features.0.weight'] = torch.zeros_like(params['features.0.weight'])\n",
    "params['features.0.weight'][0][0][0] = 2.\n",
    "\n",
    "print(server.model.state_dict()['features.0.weight'])\n",
    "\n",
    "\n",
    "print(params['features.0.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0d24b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global model zero params: 0.6850283984208128\n"
     ]
    }
   ],
   "source": [
    "pruned_c = 0.0\n",
    "total = 0.0\n",
    "for name, param in global_model.state_dict().items():\n",
    "    a = param.view(-1).to(device='cpu', copy=True).numpy()\n",
    "    pruned_c +=sum(np.where(a, 0, 1))\n",
    "    total += param.numel()\n",
    "print(f'global model zero params: {pruned_c / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27829812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6863566898009836\n"
     ]
    }
   ],
   "source": [
    "prune_c = 0.\n",
    "total = 0.\n",
    "for name,mask in global_model.mask.items():\n",
    "#     print(mask)\n",
    "    prune_c += sum(np.where(mask.to('cpu', copy=True).view(-1).numpy(), 0, 1))\n",
    "    total += mask.numel()\n",
    "    \n",
    "print(prune_c / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3d7b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb36d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41a8b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global model zero params: 0.6850283984208128\n",
      "0.6850283984208128\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "pruned_c = 0.0\n",
    "total = 0.0\n",
    "for name, param in global_model.state_dict().items():\n",
    "    a = param.view(-1).to(device='cpu', copy=True).numpy()\n",
    "    pruned_c +=sum(np.where(a, 0, 1))\n",
    "    total += param.numel()\n",
    "print(f'global model zero params: {pruned_c / total}')\n",
    "\n",
    "gcp_model = copy.deepcopy(global_model)\n",
    "\n",
    "\n",
    "\n",
    "prune_c = 0.\n",
    "total = 0.\n",
    "for name, params in gcp_model.state_dict().items():\n",
    "#     print(name)\n",
    "    prune_c += sum(np.where(params.to('cpu', copy=True).view(-1).numpy(), 0, 1))\n",
    "    total += params.numel()\n",
    "    \n",
    "print(prune_c / total)\n",
    "    \n",
    "# print('*'*10)\n",
    "# for name, mask in global_model.mask.items():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8bca0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'aggregated_masks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12771/1305552597.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# print(torch.count_nonzero(a))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggregated_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# print(torch.count_nonzero(mask))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aggregated_masks' is not defined"
     ]
    }
   ],
   "source": [
    "# for name in aggregated_masks:\n",
    "#     print(name)\n",
    "#     print(aggregated_masks[name].dtype)\n",
    "\n",
    "def count_mask(state_dict):\n",
    "    non_zero = 0.\n",
    "    total = 0.\n",
    "    for name in state_dict:\n",
    "        non_zero += torch.count_nonzero(state_dict[name])\n",
    "        total += state_dict[name].numel()\n",
    "    return 1 - non_zero / total\n",
    "# a = aggregated_masks['features.4.weight']\n",
    "print(a.shape)\n",
    "# print(torch.count_nonzero(a))\n",
    "print(count_mask(aggregated_masks))\n",
    "mask = torch.where(a>=1, 1, 0)\n",
    "# print(torch.count_nonzero(mask))\n",
    "print(count_mask(cl_mask_prarms))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
